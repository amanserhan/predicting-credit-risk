{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c12184e7-b137-4c3c-bf7c-15a215d3c7e9",
   "metadata": {},
   "source": [
    "# Predicting Credit Card Risk \n",
    "\n",
    "This project involves building a machine learning model to predict the risk for credit card applicants. The primary challenge addressed in this project is the significant class imbalance, where instances of the positive class are much less frequent than instances of the negative class. The goal is to develop a model that can accurately identify high-risk customers despite this severe imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cafd33-065b-413b-8322-ba0a265d1fd5",
   "metadata": {},
   "source": [
    "## 1. Load, Preview and Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "265835e6-024b-4754-867f-b1e7fdfdd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51df6f47-e993-4398-b164-fcd5d9f5fd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Has a car</th>\n",
       "      <th>Has a property</th>\n",
       "      <th>Children count</th>\n",
       "      <th>Income</th>\n",
       "      <th>Employment status</th>\n",
       "      <th>Education level</th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Dwelling</th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment length</th>\n",
       "      <th>Has a mobile phone</th>\n",
       "      <th>Has a work phone</th>\n",
       "      <th>Has a phone</th>\n",
       "      <th>Has an email</th>\n",
       "      <th>Job title</th>\n",
       "      <th>Family member count</th>\n",
       "      <th>Account age</th>\n",
       "      <th>Is high risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5037048</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>With parents</td>\n",
       "      <td>-16271</td>\n",
       "      <td>-3111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>2</td>\n",
       "      <td>-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5044630</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-10130</td>\n",
       "      <td>-1651</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Accountants</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5079079</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-12821</td>\n",
       "      <td>-5657</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>4</td>\n",
       "      <td>-38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5112872</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-20929</td>\n",
       "      <td>-2046</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Managers</td>\n",
       "      <td>1</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5105858</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Separated</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-16207</td>\n",
       "      <td>-515</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Gender Has a car Has a property  Children count    Income  \\\n",
       "0  5037048      M         Y              Y               0  135000.0   \n",
       "1  5044630      F         Y              N               1  135000.0   \n",
       "2  5079079      F         N              Y               2  180000.0   \n",
       "3  5112872      F         Y              Y               0  360000.0   \n",
       "4  5105858      F         N              N               0  270000.0   \n",
       "\n",
       "      Employment status                Education level        Marital status  \\\n",
       "0               Working  Secondary / secondary special               Married   \n",
       "1  Commercial associate               Higher education  Single / not married   \n",
       "2  Commercial associate  Secondary / secondary special               Married   \n",
       "3  Commercial associate               Higher education  Single / not married   \n",
       "4               Working  Secondary / secondary special             Separated   \n",
       "\n",
       "            Dwelling    Age  Employment length  Has a mobile phone  \\\n",
       "0       With parents -16271              -3111                   1   \n",
       "1  House / apartment -10130              -1651                   1   \n",
       "2  House / apartment -12821              -5657                   1   \n",
       "3  House / apartment -20929              -2046                   1   \n",
       "4  House / apartment -16207               -515                   1   \n",
       "\n",
       "   Has a work phone  Has a phone  Has an email    Job title  \\\n",
       "0                 0            0             0   Core staff   \n",
       "1                 0            0             0  Accountants   \n",
       "2                 0            0             0     Laborers   \n",
       "3                 0            0             1     Managers   \n",
       "4                 0            1             0          NaN   \n",
       "\n",
       "   Family member count  Account age  Is high risk  \n",
       "0                    2          -17             0  \n",
       "1                    2           -1             0  \n",
       "2                    4          -38             0  \n",
       "3                    1          -11             0  \n",
       "4                    1          -41             0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/amanserhan/predicting-credit-card-risk/credit_data.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d5c68fc-0583-4bba-ae94-5f8e932f120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36457 entries, 0 to 36456\n",
      "Data columns (total 20 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID                   36457 non-null  int64  \n",
      " 1   Gender               36457 non-null  object \n",
      " 2   Has a car            36457 non-null  object \n",
      " 3   Has a property       36457 non-null  object \n",
      " 4   Children count       36457 non-null  int64  \n",
      " 5   Income               36457 non-null  float64\n",
      " 6   Employment status    36457 non-null  object \n",
      " 7   Education level      36457 non-null  object \n",
      " 8   Marital status       36457 non-null  object \n",
      " 9   Dwelling             36457 non-null  object \n",
      " 10  Age                  36457 non-null  int64  \n",
      " 11  Employment length    36457 non-null  int64  \n",
      " 12  Has a mobile phone   36457 non-null  int64  \n",
      " 13  Has a work phone     36457 non-null  int64  \n",
      " 14  Has a phone          36457 non-null  int64  \n",
      " 15  Has an email         36457 non-null  int64  \n",
      " 16  Job title            25134 non-null  object \n",
      " 17  Family member count  36457 non-null  int64  \n",
      " 18  Account age          36457 non-null  int64  \n",
      " 19  Is high risk         36457 non-null  int64  \n",
      "dtypes: float64(1), int64(11), object(8)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ef922e-1a41-4ffc-befb-d7f6b49241a2",
   "metadata": {},
   "source": [
    "Let's encode the \"object\" data into integer labels in preparation for using them in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e13e566-49d9-42c7-b2d3-1b1a19050a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employment Statuses:  ['Working', 'Commercial associate', 'Pensioner', 'State servant', 'Student']\n",
      "Education Levels:  ['Secondary / secondary special', 'Higher education', 'Lower secondary', 'Incomplete higher', 'Academic degree']\n",
      "Marital Statuses:  ['Married', 'Single / not married', 'Separated', 'Civil marriage', 'Widow']\n",
      "Job Title:  ['Core staff', 'Accountants', 'Laborers', 'Managers', nan, 'Sales staff', 'Medicine staff', 'High skill tech staff', 'HR staff', 'Low-skill Laborers', 'Drivers', 'Secretaries', 'Cleaning staff', 'Cooking staff', 'Security staff', 'Private service staff', 'IT staff', 'Waiters/barmen staff', 'Realty agents']\n"
     ]
    }
   ],
   "source": [
    "#Printing the unique values in the columns in question to view all the categories for encoding\n",
    "\n",
    "employment_statuses = data['Employment status'].unique().tolist()\n",
    "education_levels = data['Education level'].unique().tolist()\n",
    "marital_statuses = data['Marital status'].unique().tolist()\n",
    "dwellings = data['Dwelling'].unique().tolist()\n",
    "job_titles = data['Job title'].unique().tolist()\n",
    "\n",
    "print(\"Employment Statuses: \", employment_statuses)\n",
    "print(\"Education Levels: \", education_levels)\n",
    "print(\"Marital Statuses: \", marital_statuses)\n",
    "print(\"Job Title: \", job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f688d286-9e04-442e-8aae-c05d1e5d569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36457 entries, 0 to 36456\n",
      "Data columns (total 17 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   ID                                  36457 non-null  int64  \n",
      " 1   Gender                              36457 non-null  int64  \n",
      " 2   Has a car                           36457 non-null  int64  \n",
      " 3   Has a property                      36457 non-null  int64  \n",
      " 4   Children count                      36457 non-null  int64  \n",
      " 5   Income                              36457 non-null  float64\n",
      " 6   Age                                 36457 non-null  int64  \n",
      " 7   Employment length                   36457 non-null  int64  \n",
      " 8   Has a mobile phone                  36457 non-null  int64  \n",
      " 9   Has a work phone                    36457 non-null  int64  \n",
      " 10  Has a phone                         36457 non-null  int64  \n",
      " 11  Has an email                        36457 non-null  int64  \n",
      " 12  Family member count                 36457 non-null  int64  \n",
      " 13  Is high risk                        36457 non-null  int64  \n",
      " 14  Employed                            36457 non-null  int64  \n",
      " 15  Completed Post-Secondary Education  36457 non-null  int64  \n",
      " 16  Married                             36457 non-null  int64  \n",
      "dtypes: float64(1), int64(16)\n",
      "memory usage: 4.7 MB\n"
     ]
    }
   ],
   "source": [
    "#Enconding the binary columns as 0s and 1s\n",
    "data['Gender'] = data['Gender'].map({'M': 1, 'F': 0})\n",
    "data['Has a car'] = data['Has a car'].map({'Y': 1, 'N': 0})\n",
    "data['Has a property'] = data['Has a property'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# Changing the \"Employment Status\" coulmn to \"Employed?\"\n",
    "data['Employed'] = data['Employment status'].map({\n",
    "    'Working': 1, \n",
    "    'Commercial associate': 1, \n",
    "    'State servant': 1,\n",
    "    'Pensioner': 0,\n",
    "    'Student': 0\n",
    "})\n",
    "data = data.drop('Employment status', axis = 1)\n",
    "\n",
    "# Changing the \"Education Level\" column to \"Completed Post-Secondary Education?\"\n",
    "data['Completed Post-Secondary Education'] = data['Education level'].map({\n",
    "    'Secondary / secondary special': 0,\n",
    "    'Lower secondary': 0,\n",
    "    'Incomplete higher': 0,\n",
    "    'Higher education': 1,\n",
    "    'Academic degree': 1\n",
    "})\n",
    "data = data.drop(\"Education level\", axis = 1)\n",
    "\n",
    "# Changing the \"Marital Status\" column to \"Married?\"\n",
    "data['Married'] = data['Marital status'].map({\n",
    "    'Single / not married': 0,\n",
    "    'Separated': 0,\n",
    "    'Widow': 0,\n",
    "    'Married': 1,\n",
    "    'Civil marriage': 1\n",
    "})\n",
    "data = data.drop(\"Marital status\", axis = 1)\n",
    "\n",
    "# Dropping the \"Dwelling\" column, since it is similar to the \"Has a property\" column in the context of this analysis\n",
    "data = data.drop(\"Dwelling\", axis = 1)\n",
    "\n",
    "# Dropping the \"Job Title\" column, since the large number of nominal categories is not very useful for our model\n",
    "data = data.drop(\"Job title\", axis = 1)\n",
    "\n",
    "# Dropping the \"Account age\" column, since the unit of measurement is unclear, which may negatively impact the accuracy of the model\n",
    "data = data.drop(\"Account age\", axis = 1)\n",
    "\n",
    "types = {\n",
    "    'Gender': \"int64\",\n",
    "    'Has a car': \"int64\",\n",
    "    'Has a property': \"int64\",\n",
    "    'Employed': \"int64\",\n",
    "    'Completed Post-Secondary Education': \"int64\",\n",
    "    'Married': \"int64\"\n",
    "}\n",
    "data.astype(types)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f6f5ef-1182-469a-958a-2a7c96000080",
   "metadata": {},
   "source": [
    "According to the dataset documentation, the \"Age\", \"Employment length\", and \"Account age\" columns are counted backwards in days, which is why the numbers are very large and negative. Let's convert that to years, positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5e9102d-8540-4ae3-9216-7cb7ae8bbdd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Has a car</th>\n",
       "      <th>Has a property</th>\n",
       "      <th>Children count</th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment length</th>\n",
       "      <th>Has a mobile phone</th>\n",
       "      <th>Has a work phone</th>\n",
       "      <th>Has a phone</th>\n",
       "      <th>Has an email</th>\n",
       "      <th>Family member count</th>\n",
       "      <th>Is high risk</th>\n",
       "      <th>Employed</th>\n",
       "      <th>Completed Post-Secondary Education</th>\n",
       "      <th>Married</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5037048</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5044630</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5079079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5112872</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5105858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Gender  Has a car  Has a property  Children count    Income  Age  \\\n",
       "0  5037048       1          1               1               0  135000.0   44   \n",
       "1  5044630       0          1               0               1  135000.0   27   \n",
       "2  5079079       0          0               1               2  180000.0   35   \n",
       "3  5112872       0          1               1               0  360000.0   57   \n",
       "4  5105858       0          0               0               0  270000.0   44   \n",
       "\n",
       "   Employment length  Has a mobile phone  Has a work phone  Has a phone  \\\n",
       "0                  8                   1                 0            0   \n",
       "1                  4                   1                 0            0   \n",
       "2                 15                   1                 0            0   \n",
       "3                  5                   1                 0            0   \n",
       "4                  1                   1                 0            1   \n",
       "\n",
       "   Has an email  Family member count  Is high risk  Employed  \\\n",
       "0             0                    2             0         1   \n",
       "1             0                    2             0         1   \n",
       "2             0                    4             0         1   \n",
       "3             1                    1             0         1   \n",
       "4             0                    1             0         1   \n",
       "\n",
       "   Completed Post-Secondary Education  Married  \n",
       "0                                   0        1  \n",
       "1                                   1        0  \n",
       "2                                   0        1  \n",
       "3                                   1        0  \n",
       "4                                   0        0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Age\"] = (np.abs(data[\"Age\"])/365).astype(\"int64\")\n",
    "\n",
    "# 'Employment Length' must be handled differently since positive values exist, indicating unemployment\n",
    "data['Employment length'] = np.where(\n",
    "    data[\"Employment length\"] >= 0, \n",
    "    0, \n",
    "    (np.abs(data[\"Employment length\"]) / 365).astype(\"int64\")\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98acd354-34e2-474a-a723-79a901aca845",
   "metadata": {},
   "source": [
    "## Analysis and Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20978493-e93e-47a2-b897-6ede64b8a61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9825836533187055\n"
     ]
    }
   ],
   "source": [
    "#Imports \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split features and target\n",
    "target  = data['Is high risk']\n",
    "features = data[['Gender', 'Has a car', 'Has a property', 'Children count', 'Income', 'Age', \n",
    "                 'Employment length', 'Has a mobile phone', 'Has a work phone', 'Has a phone', \n",
    "                 'Has an email', 'Family member count', 'Employed', \n",
    "                 'Completed Post-Secondary Education', 'Married']]\n",
    "\n",
    "# Train Test Split\n",
    "training_data, validation_data, training_labels, validation_labels = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=100\n",
    ")\n",
    "\n",
    "# Creating and training the Random Forest Classifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(training_data,training_labels)\n",
    "\n",
    "score = classifier.score(validation_data,validation_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b7284-5a13-4749-a005-d0676f0e1e5d",
   "metadata": {},
   "source": [
    "The accuracy of the model is very high at 0.98. And while this could be a good sign, it could also be a sign of overfitting. One of the best things we could to evaluate this is to test again using a new dataset the model has not yet seen. If the accuracy drops on this new dataset, it's likely a sign of overfitting. But unfortunately, we don't have access to that. So instead, let's try some other steps to validate the performance of the model, starting with its confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04bd9759-5646-4dd8-abfb-697e2e3823f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7147   20]\n",
      " [ 107   18]]\n",
      "Is high risk\n",
      "0    35841\n",
      "1      616\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict on the validation set\n",
    "validation_predictions = classifier.predict(validation_data)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(validation_labels, validation_predictions)\n",
    "print(conf_matrix)\n",
    "print(data['Is high risk'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d9be4-e6c3-4301-96a3-f984c7ce2d60",
   "metadata": {},
   "source": [
    "The number of positive cases in the data seems to be orders of magnitude lower than the negatives. Additionally, the number of false positives are more than five times the number of false negatives. This indicates the the model is biased towards identifying non high-risk cases, and for good reason. There are much more negative cases in the data than positive. There is a very pronounced class imbalance in the data. To examine its effects further, let's calculate the precision, recall, and f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9be3aa81-de26-4af6-a28a-433b4427cc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.47368421052631576\n",
      "Recall (Sensitivity): 0.144\n",
      "F1-Score: 0.22085889570552147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(validation_labels, validation_predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall (sensitivity)\n",
    "recall = recall_score(validation_labels, validation_predictions)\n",
    "print(\"Recall (Sensitivity):\", recall)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(validation_labels, validation_predictions)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1041f4d7-c4fc-4e74-bf96-968ba1986e40",
   "metadata": {},
   "source": [
    "The precision is pretty low, at around 0.4. Of all the instances the model predicted the classification to be positive, it was actually positive only 40% of the time. \n",
    "\n",
    "Recall is even lower, at around 0.14. Out of all the instances that are truly positive, the model only predicted 14% of them correctly.\n",
    "\n",
    "Based on these results, we can conclude that our main issues are class imbalance and poor model performance on the minority class. The model is not effectively identifying the \"high-risk\" cases, which suggests the model might be over-reliant on predicting the majority class (non-high-risk) correctly.\n",
    "\n",
    "High overall accuracy combined with low precision, recall, and F1-score for the minority class is a sign of a model that is biased towards the majority class rather than overfitting in the traditional sense.\n",
    "\n",
    "Some of the solutions we can implement to mitigate this include resampling techniques, either oversampling the minority class or undersampling the majority class. A second option is adjusting the \"class_weight\" parameter in the model. Let's start with the second option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51ecc307-3e0c-47dc-86cc-20b1c4bfb08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9591332967635765\n",
      "Precision: 0.18315018315018314\n",
      "Recall (Sensitivity): 0.4\n",
      "F1-Score: 0.25125628140703515\n"
     ]
    }
   ],
   "source": [
    "# Creating a Random Forest Classifier with balanced class weights\n",
    "classifier2 = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# Train the classifier\n",
    "classifier2.fit(training_data, training_labels)\n",
    "\n",
    "# Evaluate the classifier\n",
    "score2 = classifier2.score(validation_data, validation_labels)\n",
    "\n",
    "# Generating predictions for the classifier\n",
    "validation_predictions2 = classifier2.predict(validation_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "print(\"Accuracy:\", score2)\n",
    "\n",
    "# Calculate precision\n",
    "precision2 = precision_score(validation_labels, validation_predictions2)\n",
    "print(\"Precision:\", precision2)\n",
    "\n",
    "# Calculate recall (sensitivity)\n",
    "recall2 = recall_score(validation_labels, validation_predictions2)\n",
    "print(\"Recall (Sensitivity):\", recall2)\n",
    "\n",
    "# Calculate F1-score\n",
    "f12 = f1_score(validation_labels, validation_predictions2)\n",
    "print(\"F1-Score:\", f12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6ba1e-a528-42e3-85fa-90201c71a991",
   "metadata": {},
   "source": [
    "The precision has dropped to less than half, which means the model now has more false positives. This is expected because the model is now predicting more \"high-risk\" cases due to the increased weight on the minority class. Recall improved substantially, meaning the model is now capturing more true \"high-risk\" cases. This is a positive outcome as it indicates the model is better at identifying the minority class. The F1-score improved slightly, indicating a better balance between precision and recall. \n",
    "\n",
    "In our case, it's important to improve the model's performance on the minority class because even though the \"is high risk\" positive outcome is generally less common, the model is not useful if it mislabels these few critical points as negative. This is why we must look at precision, recall and f1 more closely than accuracy, since it's pretty easy to be accurate when the overwhelming majority of points are in one class. There is still room for improvement, so let's try a different method, resampling techniques, and see if that improves our metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "994b3cf4-57cd-43af-900d-21828afd361c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9561162918266594\n",
      "Precision: 0.15789473684210525\n",
      "Recall (Sensitivity): 0.36\n",
      "F1-Score: 0.21951219512195122\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Instantiating ADASYN\n",
    "adasyn = ADASYN(sampling_strategy=\"minority\", random_state= 42, n_neighbors=15)\n",
    "\n",
    "# Resampling the training data\n",
    "training_data_resampled, training_labels_resampled = adasyn.fit_resample(training_data, training_labels)\n",
    "\n",
    "# Creating a Random Forest Classifier for the resampled data\n",
    "classifier3 = RandomForestClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "classifier3.fit(training_data_resampled, training_labels_resampled)\n",
    "\n",
    "# Evaluate the classifier\n",
    "score3 = classifier3.score(validation_data, validation_labels)\n",
    "\n",
    "# Generating predictions for the classifier\n",
    "validation_predictions3 = classifier3.predict(validation_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "print(\"Accuracy:\", score3)\n",
    "\n",
    "# Calculate precision\n",
    "precision3 = precision_score(validation_labels, validation_predictions3)\n",
    "print(\"Precision:\", precision3)\n",
    "\n",
    "# Calculate recall (sensitivity)\n",
    "recall3 = recall_score(validation_labels, validation_predictions3)\n",
    "print(\"Recall (Sensitivity):\", recall3)\n",
    "\n",
    "# Calculate F1-score\n",
    "f13 = f1_score(validation_labels, validation_predictions3)\n",
    "print(\"F1-Score:\", f13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f817b-fc8a-4510-86e7-f02c449c1cd0",
   "metadata": {},
   "source": [
    "The recall in this case is a improvement from the first model, but not as good as our results from setting class_weight='balanced' in our second model. Knowing this, let's go back to this strategy, this time balancing the individual bootstrap samples generated by the classifier as opposed to the dataset as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "866be495-9e8a-4c53-9f6d-dda5b3957072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9585847504114098\n",
      "Precision: 0.1827956989247312\n",
      "Recall (Sensitivity): 0.408\n",
      "F1-Score: 0.2524752475247525\n"
     ]
    }
   ],
   "source": [
    "# Creating a Random Forest Classifier with balanced subsample weights\n",
    "classifier4 = RandomForestClassifier(class_weight='balanced_subsample')\n",
    "\n",
    "# Train the classifier\n",
    "classifier4.fit(training_data, training_labels)\n",
    "\n",
    "# Evaluate the classifier\n",
    "score4 = classifier4.score(validation_data, validation_labels)\n",
    "\n",
    "# Generating predictions for the classifier\n",
    "validation_predictions4 = classifier4.predict(validation_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "print(\"Accuracy:\", score4)\n",
    "\n",
    "# Calculate precision\n",
    "precision4 = precision_score(validation_labels, validation_predictions4)\n",
    "print(\"Precision:\", precision4)\n",
    "\n",
    "# Calculate recall (sensitivity)\n",
    "recall4 = recall_score(validation_labels, validation_predictions4)\n",
    "print(\"Recall (Sensitivity):\", recall4)\n",
    "\n",
    "# Calculate F1-score\n",
    "f14 = f1_score(validation_labels, validation_predictions4)\n",
    "print(\"F1-Score:\", f14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc8b1c-3870-44c3-a6a9-0323402bda2f",
   "metadata": {},
   "source": [
    "As expected, there's a slight improvement from our second model, which balanced the dataset as a whole before the random subsamples were taken. For an even more dramatic improvement to our recall, we can try a balanced random forest classifier from the imbalanced learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "920edaea-7d9f-4738-b107-bdda21de9bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9585847504114098\n",
      "Precision: 0.03878406708595388\n",
      "Recall (Sensitivity): 0.592\n",
      "F1-Score: 0.07279881947860305\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# Creating a Random Forest Classifier with balanced subsample weights\n",
    "classifier5 = BalancedRandomForestClassifier(sampling_strategy = 'auto', replacement = False, bootstrap = True)\n",
    "\n",
    "# Train the classifier\n",
    "classifier5.fit(training_data, training_labels)\n",
    "\n",
    "# Evaluate the classifier\n",
    "score5 = classifier5.score(validation_data, validation_labels)\n",
    "\n",
    "# Generating predictions for the classifier\n",
    "validation_predictions5 = classifier5.predict(validation_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "print(\"Accuracy:\", score4)\n",
    "\n",
    "# Calculate precision\n",
    "precision5 = precision_score(validation_labels, validation_predictions5)\n",
    "print(\"Precision:\", precision5)\n",
    "\n",
    "# Calculate recall (sensitivity)\n",
    "recall5 = recall_score(validation_labels, validation_predictions5)\n",
    "print(\"Recall (Sensitivity):\", recall5)\n",
    "\n",
    "# Calculate F1-score\n",
    "f15 = f1_score(validation_labels, validation_predictions5)\n",
    "print(\"F1-Score:\", f15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7292786-e404-4263-a47c-92899e1b84f6",
   "metadata": {},
   "source": [
    "As expected, our recall increased quite a bit, with a substantial blow to our precision and f1 score. The very low precision indicates the model is predicted many false positives. The recall score means that around 61% of our positive cases are predicted correctly. For a more complete picture, let's also perform cross validation to infer how the model would perform on new unseen data. We will use stratified cross validation since the data has a class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12bc3fc2-53b6-430a-bb5e-03bf8e843153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9621807008064451"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(classifier4, training_data, y=training_labels, cv = stratified_kfold, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbf350b-bd8b-472f-8251-3e24e587f95c",
   "metadata": {},
   "source": [
    "A cross-validation score of 73% is not terrible, but there's still much room for improvement. Next steps for this project could be exploring other techniques for dealing with class imbalances, such as other resampling methods we have not tried (SMOTE, undersampling the majority class, etc), combining ensemble methods with resampling, and tuning some of the hyperparameters. But for now, we'll call it a wrap."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
